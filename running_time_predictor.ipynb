{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T09:49:00.740214Z",
     "start_time": "2024-12-16T09:49:00.691187Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import activity_data_importer\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "# reload my module each time I execute to get new changes without restarting kernel\n",
    "importlib.reload(activity_data_importer)\n",
    "\n",
    "# import data and filter out erroneous rows\n",
    "df = activity_data_importer.import_activity_data()\n",
    "filtered_df = activity_data_importer.drop_erroneous_rows(df)\n",
    "print(f\"Dropped {len(df.index) - len(filtered_df.index)} records due to erroneous measurements.\")\n",
    "df = filtered_df"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 4 records due to erroneous measurements.\n"
     ]
    }
   ],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T09:49:00.747579Z",
     "start_time": "2024-12-16T09:49:00.744590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# creating maps for converting string types to numbers and back\n",
    "\n",
    "# getting all unique values in the columns\n",
    "activity_types = set(df['Activity Type'].unique())\n",
    "event_types = set(df['Event Type'].unique())\n",
    "\n",
    "# create the empty maps\n",
    "int_to_activity_type = {}\n",
    "activity_type_to_int = {}\n",
    "\n",
    "int_to_event_type = {}\n",
    "event_type_to_int = {}\n",
    "\n",
    "# fill the maps\n",
    "for index, activity_type in enumerate(activity_types):\n",
    "    int_to_activity_type[index] = activity_type\n",
    "    activity_type_to_int[activity_type] = index\n",
    "\n",
    "for index, event_type in enumerate(event_types):\n",
    "    int_to_event_type[index] = event_type\n",
    "    event_type_to_int[event_type] = index"
   ],
   "id": "3277194a97a01197",
   "outputs": [],
   "execution_count": 209
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T09:49:00.805802Z",
     "start_time": "2024-12-16T09:49:00.790535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import timezone, datetime\n",
    "\n",
    "# do any conversions that are required for feeding the data into our model\n",
    "\n",
    "# convert duration column to total seconds\n",
    "df['Duration (h:m:s)'] = df['Duration (h:m:s)'].apply(lambda td: td.total_seconds())\n",
    "df.rename(columns={'Duration (h:m:s)': 'Duration (s)'}, inplace=True)\n",
    "\n",
    "# convert string columns into numbers\n",
    "df['Activity Type'] = df['Activity Type'].apply(lambda act: activity_type_to_int[act])\n",
    "df['Event Type'] = df['Event Type'].apply(lambda evt: event_type_to_int[evt])\n",
    "\n",
    "# convert Start Time to UTC timestamp\n",
    "df['Start Time'] = df['Start Time'].apply(lambda dt: dt.replace(tzinfo=timezone.utc).timestamp())\n",
    "\n",
    "# fill all NaN values with a 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# dropping columns irrelevant to training the model\n",
    "columns_to_drop = ['Min. Temp (°C)', 'Max. Temp (°C)', 'Stride Length', 'Steps',\n",
    "                   'Avg. Cadence (rpm)', 'Max. Cadence (rpm)', 'Avg. Run Cadence', 'Max. Run Cadence',\n",
    "                   'VO2max', 'Aerobic Training Effect', 'Anaerobic Training Effect', 'End Time']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# dropping rows with specific activity types since they are not interesting for training\n",
    "activity_types_to_drop = [activity_type_to_int['Other'], activity_type_to_int['Transition'],\n",
    "                          activity_type_to_int['Walking'], activity_type_to_int['Strength Training']]\n",
    "df = df[~df['Activity Type'].isin(activity_types_to_drop)]\n",
    "\n",
    "df"
   ],
   "id": "a04d2d60d27a5955",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Start Time  Duration (s)  Activity Type  Event Type  Distance (km)  \\\n",
       "1     1.733045e+09        2142.0              2           1        9.95481   \n",
       "2     1.733044e+09         665.0              2           2        1.57320   \n",
       "3     1.732953e+09        6933.0              2           2       23.37705   \n",
       "4     1.732893e+09        3526.0              7           2       20.12749   \n",
       "6     1.732776e+09        1627.0              2           2        5.66210   \n",
       "...            ...           ...            ...         ...            ...   \n",
       "1096  1.637765e+09        2727.0              5           2        8.05562   \n",
       "1097  1.637688e+09        5121.0              2           2       14.81816   \n",
       "1098  1.637493e+09        7486.0              5           2       20.10268   \n",
       "1099  1.637391e+09        2688.0              5           2        8.14423   \n",
       "1100  1.637167e+09        2537.0              2           2        7.80808   \n",
       "\n",
       "      Average Speed (km/h)  Average Moving Speed (km/h)  Max. Speed (km/h)  \\\n",
       "1                16.729199                    16.762247          23.850000   \n",
       "2                 8.517600                     9.486633          13.435200   \n",
       "3                12.139200                    12.177149          15.685200   \n",
       "4                20.548801                    20.702561          43.768800   \n",
       "6                12.528000                    12.545405          13.435200   \n",
       "...                    ...                          ...                ...   \n",
       "1096             10.634400                    10.646061          16.830001   \n",
       "1097             10.414800                    11.863943          20.188799   \n",
       "1098              9.666000                    10.212630          17.701199   \n",
       "1099             10.904400                    10.964320          17.265600   \n",
       "1100             11.080800                    11.755036          13.705200   \n",
       "\n",
       "      Elevation Gain (m)  Elevation Loss (m)  Elevation Min. (m)  \\\n",
       "1                  79.45               79.33               221.2   \n",
       "2                   8.68               54.26               211.0   \n",
       "3                 472.01              439.17               141.4   \n",
       "4                 374.48              328.59               174.2   \n",
       "6                  54.83               54.98               176.6   \n",
       "...                  ...                 ...                 ...   \n",
       "1096              167.00              157.00               222.6   \n",
       "1097               59.00               52.00               153.8   \n",
       "1098              415.00              400.00               172.6   \n",
       "1099              180.00              171.00               396.2   \n",
       "1100               40.00               36.00               127.4   \n",
       "\n",
       "      Elevation Max. (m)  Max. Heart Rate (bpm)  Average Heart Rate (bpm)  \\\n",
       "1                  275.8                  186.0                     163.0   \n",
       "2                  216.8                  125.0                     106.0   \n",
       "3                  370.6                  166.0                     148.0   \n",
       "4                  360.8                  166.0                     128.0   \n",
       "6                  204.6                  165.0                     150.0   \n",
       "...                  ...                    ...                       ...   \n",
       "1096               329.6                  163.0                     147.0   \n",
       "1097               187.2                  164.0                     144.0   \n",
       "1098               321.4                  169.0                     141.0   \n",
       "1099               498.8                  164.0                     146.0   \n",
       "1100               152.4                  166.0                     151.0   \n",
       "\n",
       "      Calories  Avg. Temp (°C)  \n",
       "1          615       11.490340  \n",
       "2          106       22.902810  \n",
       "3         1500       17.631282  \n",
       "4          516       13.000000  \n",
       "6          360       16.184515  \n",
       "...        ...             ...  \n",
       "1096       500       21.058698  \n",
       "1097       838       19.255316  \n",
       "1098      1082       17.494922  \n",
       "1099       486       20.725323  \n",
       "1100       488       18.580250  \n",
       "\n",
       "[878 rows x 16 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Duration (s)</th>\n",
       "      <th>Activity Type</th>\n",
       "      <th>Event Type</th>\n",
       "      <th>Distance (km)</th>\n",
       "      <th>Average Speed (km/h)</th>\n",
       "      <th>Average Moving Speed (km/h)</th>\n",
       "      <th>Max. Speed (km/h)</th>\n",
       "      <th>Elevation Gain (m)</th>\n",
       "      <th>Elevation Loss (m)</th>\n",
       "      <th>Elevation Min. (m)</th>\n",
       "      <th>Elevation Max. (m)</th>\n",
       "      <th>Max. Heart Rate (bpm)</th>\n",
       "      <th>Average Heart Rate (bpm)</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Avg. Temp (°C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.733045e+09</td>\n",
       "      <td>2142.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.95481</td>\n",
       "      <td>16.729199</td>\n",
       "      <td>16.762247</td>\n",
       "      <td>23.850000</td>\n",
       "      <td>79.45</td>\n",
       "      <td>79.33</td>\n",
       "      <td>221.2</td>\n",
       "      <td>275.8</td>\n",
       "      <td>186.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>615</td>\n",
       "      <td>11.490340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.733044e+09</td>\n",
       "      <td>665.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.57320</td>\n",
       "      <td>8.517600</td>\n",
       "      <td>9.486633</td>\n",
       "      <td>13.435200</td>\n",
       "      <td>8.68</td>\n",
       "      <td>54.26</td>\n",
       "      <td>211.0</td>\n",
       "      <td>216.8</td>\n",
       "      <td>125.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106</td>\n",
       "      <td>22.902810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.732953e+09</td>\n",
       "      <td>6933.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23.37705</td>\n",
       "      <td>12.139200</td>\n",
       "      <td>12.177149</td>\n",
       "      <td>15.685200</td>\n",
       "      <td>472.01</td>\n",
       "      <td>439.17</td>\n",
       "      <td>141.4</td>\n",
       "      <td>370.6</td>\n",
       "      <td>166.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>17.631282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.732893e+09</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>20.12749</td>\n",
       "      <td>20.548801</td>\n",
       "      <td>20.702561</td>\n",
       "      <td>43.768800</td>\n",
       "      <td>374.48</td>\n",
       "      <td>328.59</td>\n",
       "      <td>174.2</td>\n",
       "      <td>360.8</td>\n",
       "      <td>166.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>516</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.732776e+09</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.66210</td>\n",
       "      <td>12.528000</td>\n",
       "      <td>12.545405</td>\n",
       "      <td>13.435200</td>\n",
       "      <td>54.83</td>\n",
       "      <td>54.98</td>\n",
       "      <td>176.6</td>\n",
       "      <td>204.6</td>\n",
       "      <td>165.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>360</td>\n",
       "      <td>16.184515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>1.637765e+09</td>\n",
       "      <td>2727.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8.05562</td>\n",
       "      <td>10.634400</td>\n",
       "      <td>10.646061</td>\n",
       "      <td>16.830001</td>\n",
       "      <td>167.00</td>\n",
       "      <td>157.00</td>\n",
       "      <td>222.6</td>\n",
       "      <td>329.6</td>\n",
       "      <td>163.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>500</td>\n",
       "      <td>21.058698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1.637688e+09</td>\n",
       "      <td>5121.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14.81816</td>\n",
       "      <td>10.414800</td>\n",
       "      <td>11.863943</td>\n",
       "      <td>20.188799</td>\n",
       "      <td>59.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>153.8</td>\n",
       "      <td>187.2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>838</td>\n",
       "      <td>19.255316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>1.637493e+09</td>\n",
       "      <td>7486.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20.10268</td>\n",
       "      <td>9.666000</td>\n",
       "      <td>10.212630</td>\n",
       "      <td>17.701199</td>\n",
       "      <td>415.00</td>\n",
       "      <td>400.00</td>\n",
       "      <td>172.6</td>\n",
       "      <td>321.4</td>\n",
       "      <td>169.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1082</td>\n",
       "      <td>17.494922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>1.637391e+09</td>\n",
       "      <td>2688.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8.14423</td>\n",
       "      <td>10.904400</td>\n",
       "      <td>10.964320</td>\n",
       "      <td>17.265600</td>\n",
       "      <td>180.00</td>\n",
       "      <td>171.00</td>\n",
       "      <td>396.2</td>\n",
       "      <td>498.8</td>\n",
       "      <td>164.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>486</td>\n",
       "      <td>20.725323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>1.637167e+09</td>\n",
       "      <td>2537.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7.80808</td>\n",
       "      <td>11.080800</td>\n",
       "      <td>11.755036</td>\n",
       "      <td>13.705200</td>\n",
       "      <td>40.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>127.4</td>\n",
       "      <td>152.4</td>\n",
       "      <td>166.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>488</td>\n",
       "      <td>18.580250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>878 rows × 16 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T09:49:00.830801Z",
     "start_time": "2024-12-16T09:49:00.827996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# getting all 10km races\n",
    "ten_k_races = df.loc[\n",
    "    (df['Activity Type'] == activity_type_to_int['Running']) &\n",
    "    (df['Event Type'] == event_type_to_int['Race']) &\n",
    "    (df['Distance (km)'] >= 9) &\n",
    "    (df['Distance (km)'] <= 11)\n",
    "]"
   ],
   "id": "fd23f8af3c547129",
   "outputs": [],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T09:49:00.869220Z",
     "start_time": "2024-12-16T09:49:00.860166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# creating a list of 3 month blocks before each race\n",
    "ten_k_race_training_blocks = ten_k_races['Start Time'].apply(lambda ts: datetime.fromtimestamp(ts, tz=timezone.utc))\n",
    "ten_k_race_training_blocks = ten_k_race_training_blocks.apply(lambda dt: dt - relativedelta(months=3))\n",
    "ten_k_race_training_blocks = pd.DataFrame({\n",
    "    'Training Block Start': ten_k_race_training_blocks.apply(lambda dt: dt.replace(tzinfo=timezone.utc).timestamp()),\n",
    "    'Race Date': ten_k_races['Start Time'],\n",
    "})\n",
    "\n",
    "# getting all activities within each 3 month block\n",
    "def get_training_block_activities():\n",
    "    training_block_activities_list = []\n",
    "    for index, row in ten_k_race_training_blocks.iterrows():\n",
    "        # getting all activities within a single training block excluding the race itself\n",
    "        training_block_activities = df[\n",
    "            (df['Start Time'] >= row['Training Block Start']) &\n",
    "            (df['Start Time'] < row['Race Date'])\n",
    "        ]\n",
    "        training_block_activities_list.append(training_block_activities)\n",
    "    return training_block_activities_list\n",
    "\n",
    "# creating a series of training block activities: [[block1_activities], [block2_activities], ...]\n",
    "ten_k_race_training_block_activities = pd.Series(get_training_block_activities())"
   ],
   "id": "399f221859b82750",
   "outputs": [],
   "execution_count": 212
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T09:49:00.905109Z",
     "start_time": "2024-12-16T09:49:00.884663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# normalize and scale input data to resolve big differences in feature magnitudes\n",
    "# i.e. Start Time is a big number (> 1 billion), event type is a very small number (0..2)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "ten_k_race_training_block_activities = ten_k_race_training_block_activities.apply(\n",
    "    lambda block: block.drop(['Start Time', 'Event Type', 'Duration (s)'], axis='columns')\n",
    ")\n",
    "ten_k_race_training_block_activities = ten_k_race_training_block_activities.apply(\n",
    "    lambda block: pd.DataFrame(scaler.fit_transform(block))\n",
    ")\n",
    "\n",
    "ten_k_race_training_block_activities.iloc[0]"
   ],
   "id": "8d163ae3bda518f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0  -0.839964 -1.035303 -1.424867 -1.206281 -0.931412 -1.160686 -0.845714   \n",
       "1  -0.839964  0.315744 -0.763913 -0.735546 -0.803828  1.864899  1.922126   \n",
       "2   0.878144  0.114389  0.770867  0.756068  0.788626  1.228020  1.126959   \n",
       "3  -0.839964 -0.781939 -0.692956 -0.671115 -0.931412 -0.859322 -0.840536   \n",
       "4  -0.839964 -0.294146  0.116483  0.121818 -0.876092 -0.818248 -0.726633   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "67 -0.839964  1.514541 -0.582578 -0.566231 -0.540903 -0.206705 -0.098941   \n",
       "68 -0.839964 -0.853447 -0.541186 -0.526326 -0.891402 -1.152392 -1.170454   \n",
       "69 -0.839964 -0.820648 -0.459060 -0.447998 -0.813218 -1.153176 -1.163694   \n",
       "70 -0.839964 -0.818842 -0.474171 -0.455062 -0.807502 -1.142728 -1.184620   \n",
       "71  0.878144  4.019454  1.136822  1.162883  0.375253  0.581737  0.267649   \n",
       "\n",
       "          7         8         9         10        11        12  \n",
       "0   1.149955 -0.263091 -3.747945 -2.973062 -1.301316  0.499821  \n",
       "1  -0.118067  1.146375 -0.096482  0.510293  1.448957 -0.524620  \n",
       "2   0.479506  1.056565 -0.096482 -1.148448 -0.492412 -1.424639  \n",
       "3   0.523231 -0.374895 -0.185542  0.676167 -0.800190 -0.805777  \n",
       "4   0.840237 -0.114630 -0.274602  0.427356 -0.220147 -0.319589  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "67 -1.739532 -1.487439  1.862840  1.920223  3.928939  1.712396  \n",
       "68 -2.191356 -1.896166 -0.452722  0.759104 -0.948160  1.101452  \n",
       "69 -2.143988 -1.910828  0.705059  1.007915 -0.877135  1.995037  \n",
       "70 -1.910788 -1.784361  0.615999  0.676167 -0.902783  1.029377  \n",
       "71 -3.189742 -2.143601 -0.808962 -1.231385  1.914571  2.073386  \n",
       "\n",
       "[72 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.839964</td>\n",
       "      <td>-1.035303</td>\n",
       "      <td>-1.424867</td>\n",
       "      <td>-1.206281</td>\n",
       "      <td>-0.931412</td>\n",
       "      <td>-1.160686</td>\n",
       "      <td>-0.845714</td>\n",
       "      <td>1.149955</td>\n",
       "      <td>-0.263091</td>\n",
       "      <td>-3.747945</td>\n",
       "      <td>-2.973062</td>\n",
       "      <td>-1.301316</td>\n",
       "      <td>0.499821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.839964</td>\n",
       "      <td>0.315744</td>\n",
       "      <td>-0.763913</td>\n",
       "      <td>-0.735546</td>\n",
       "      <td>-0.803828</td>\n",
       "      <td>1.864899</td>\n",
       "      <td>1.922126</td>\n",
       "      <td>-0.118067</td>\n",
       "      <td>1.146375</td>\n",
       "      <td>-0.096482</td>\n",
       "      <td>0.510293</td>\n",
       "      <td>1.448957</td>\n",
       "      <td>-0.524620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878144</td>\n",
       "      <td>0.114389</td>\n",
       "      <td>0.770867</td>\n",
       "      <td>0.756068</td>\n",
       "      <td>0.788626</td>\n",
       "      <td>1.228020</td>\n",
       "      <td>1.126959</td>\n",
       "      <td>0.479506</td>\n",
       "      <td>1.056565</td>\n",
       "      <td>-0.096482</td>\n",
       "      <td>-1.148448</td>\n",
       "      <td>-0.492412</td>\n",
       "      <td>-1.424639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.839964</td>\n",
       "      <td>-0.781939</td>\n",
       "      <td>-0.692956</td>\n",
       "      <td>-0.671115</td>\n",
       "      <td>-0.931412</td>\n",
       "      <td>-0.859322</td>\n",
       "      <td>-0.840536</td>\n",
       "      <td>0.523231</td>\n",
       "      <td>-0.374895</td>\n",
       "      <td>-0.185542</td>\n",
       "      <td>0.676167</td>\n",
       "      <td>-0.800190</td>\n",
       "      <td>-0.805777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.839964</td>\n",
       "      <td>-0.294146</td>\n",
       "      <td>0.116483</td>\n",
       "      <td>0.121818</td>\n",
       "      <td>-0.876092</td>\n",
       "      <td>-0.818248</td>\n",
       "      <td>-0.726633</td>\n",
       "      <td>0.840237</td>\n",
       "      <td>-0.114630</td>\n",
       "      <td>-0.274602</td>\n",
       "      <td>0.427356</td>\n",
       "      <td>-0.220147</td>\n",
       "      <td>-0.319589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.839964</td>\n",
       "      <td>1.514541</td>\n",
       "      <td>-0.582578</td>\n",
       "      <td>-0.566231</td>\n",
       "      <td>-0.540903</td>\n",
       "      <td>-0.206705</td>\n",
       "      <td>-0.098941</td>\n",
       "      <td>-1.739532</td>\n",
       "      <td>-1.487439</td>\n",
       "      <td>1.862840</td>\n",
       "      <td>1.920223</td>\n",
       "      <td>3.928939</td>\n",
       "      <td>1.712396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.839964</td>\n",
       "      <td>-0.853447</td>\n",
       "      <td>-0.541186</td>\n",
       "      <td>-0.526326</td>\n",
       "      <td>-0.891402</td>\n",
       "      <td>-1.152392</td>\n",
       "      <td>-1.170454</td>\n",
       "      <td>-2.191356</td>\n",
       "      <td>-1.896166</td>\n",
       "      <td>-0.452722</td>\n",
       "      <td>0.759104</td>\n",
       "      <td>-0.948160</td>\n",
       "      <td>1.101452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.839964</td>\n",
       "      <td>-0.820648</td>\n",
       "      <td>-0.459060</td>\n",
       "      <td>-0.447998</td>\n",
       "      <td>-0.813218</td>\n",
       "      <td>-1.153176</td>\n",
       "      <td>-1.163694</td>\n",
       "      <td>-2.143988</td>\n",
       "      <td>-1.910828</td>\n",
       "      <td>0.705059</td>\n",
       "      <td>1.007915</td>\n",
       "      <td>-0.877135</td>\n",
       "      <td>1.995037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.839964</td>\n",
       "      <td>-0.818842</td>\n",
       "      <td>-0.474171</td>\n",
       "      <td>-0.455062</td>\n",
       "      <td>-0.807502</td>\n",
       "      <td>-1.142728</td>\n",
       "      <td>-1.184620</td>\n",
       "      <td>-1.910788</td>\n",
       "      <td>-1.784361</td>\n",
       "      <td>0.615999</td>\n",
       "      <td>0.676167</td>\n",
       "      <td>-0.902783</td>\n",
       "      <td>1.029377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.878144</td>\n",
       "      <td>4.019454</td>\n",
       "      <td>1.136822</td>\n",
       "      <td>1.162883</td>\n",
       "      <td>0.375253</td>\n",
       "      <td>0.581737</td>\n",
       "      <td>0.267649</td>\n",
       "      <td>-3.189742</td>\n",
       "      <td>-2.143601</td>\n",
       "      <td>-0.808962</td>\n",
       "      <td>-1.231385</td>\n",
       "      <td>1.914571</td>\n",
       "      <td>2.073386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T09:49:00.943305Z",
     "start_time": "2024-12-16T09:49:00.938752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "max_input_size = 0\n",
    "\n",
    "for index, row in ten_k_races.reset_index().iterrows():\n",
    "    x = np.array(ten_k_race_training_block_activities.iloc[index])\n",
    "    if max_input_size < x.shape[0]:\n",
    "        max_input_size = x.shape[0]\n",
    "    X.append(np.array(ten_k_race_training_block_activities.iloc[index]))\n",
    "\n",
    "# create reference shape, second dimension is constant\n",
    "input_shape = (max_input_size, X[0].shape[1])\n",
    "\n",
    "# pad each input with 0 rows to ensure each input has a consistent shape\n",
    "for i, x in enumerate(X):\n",
    "    result = np.zeros(input_shape)\n",
    "    result[:x.shape[0],:x.shape[1]] = x\n",
    "    X[i] = result\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(ten_k_races['Duration (s)'])\n",
    "\n",
    "print(X.shape, y.shape)"
   ],
   "id": "f261336ea83f0352",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 88, 13) (10,)\n"
     ]
    }
   ],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T09:49:01.087515Z",
     "start_time": "2024-12-16T09:49:00.964496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=100, input_shape=input_shape))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ],
   "id": "e325157d7e455a8d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T09:49:07.032373Z",
     "start_time": "2024-12-16T09:49:01.091676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_training_data, test_training_data = X[:-2], X[-2:]\n",
    "train_racing_data, test_racing_data = y[:-2], y[-2:]\n",
    "\n",
    "print(train_training_data.shape, test_training_data.shape)\n",
    "print(train_racing_data.shape, test_racing_data.shape)\n",
    "\n",
    "model.fit(train_training_data, train_racing_data, epochs=200)"
   ],
   "id": "1f9d817523f2da31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 88, 13) (2, 88, 13)\n",
      "(8,) (2,)\n",
      "Epoch 1/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 637ms/step - loss: 4772673.5000 - mae: 2183.1309\n",
      "Epoch 2/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4772571.0000 - mae: 2183.1069\n",
      "Epoch 3/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4772493.0000 - mae: 2183.0891\n",
      "Epoch 4/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4772397.0000 - mae: 2183.0669\n",
      "Epoch 5/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4772240.5000 - mae: 2183.0310\n",
      "Epoch 6/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4772150.0000 - mae: 2183.0098\n",
      "Epoch 7/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4771917.0000 - mae: 2182.9563\n",
      "Epoch 8/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4771602.5000 - mae: 2182.8843\n",
      "Epoch 9/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4771239.0000 - mae: 2182.8000\n",
      "Epoch 10/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4770641.0000 - mae: 2182.6628\n",
      "Epoch 11/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4769704.0000 - mae: 2182.4487\n",
      "Epoch 12/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4768139.0000 - mae: 2182.0901\n",
      "Epoch 13/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4765386.0000 - mae: 2181.4624\n",
      "Epoch 14/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 4761235.0000 - mae: 2180.5203\n",
      "Epoch 15/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4756035.0000 - mae: 2179.3198\n",
      "Epoch 16/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4753748.0000 - mae: 2178.7866\n",
      "Epoch 17/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4749291.5000 - mae: 2177.7627\n",
      "Epoch 18/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4747969.0000 - mae: 2177.4692\n",
      "Epoch 19/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 4745897.0000 - mae: 2177.0054\n",
      "Epoch 20/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4744714.5000 - mae: 2176.7109\n",
      "Epoch 21/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4742373.0000 - mae: 2176.1934\n",
      "Epoch 22/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4740488.5000 - mae: 2175.7520\n",
      "Epoch 23/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4738403.0000 - mae: 2175.2715\n",
      "Epoch 24/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4737070.5000 - mae: 2174.9604\n",
      "Epoch 25/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 4735129.5000 - mae: 2174.5122\n",
      "Epoch 26/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4733401.0000 - mae: 2174.1182\n",
      "Epoch 27/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4732803.0000 - mae: 2173.9768\n",
      "Epoch 28/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4731322.0000 - mae: 2173.6245\n",
      "Epoch 29/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4729217.0000 - mae: 2173.1538\n",
      "Epoch 30/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4725307.0000 - mae: 2172.2451\n",
      "Epoch 31/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4724815.5000 - mae: 2172.1465\n",
      "Epoch 32/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4725304.0000 - mae: 2172.2625\n",
      "Epoch 33/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4722418.0000 - mae: 2171.6108\n",
      "Epoch 34/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4722247.0000 - mae: 2171.5410\n",
      "Epoch 35/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4718682.0000 - mae: 2170.7166\n",
      "Epoch 36/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4716006.0000 - mae: 2170.1067\n",
      "Epoch 37/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4718721.0000 - mae: 2170.7314\n",
      "Epoch 38/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4714536.0000 - mae: 2169.7705\n",
      "Epoch 39/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4716711.0000 - mae: 2170.2681\n",
      "Epoch 40/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4712654.0000 - mae: 2169.3335\n",
      "Epoch 41/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4714375.5000 - mae: 2169.7336\n",
      "Epoch 42/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4710964.0000 - mae: 2168.9631\n",
      "Epoch 43/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4712315.5000 - mae: 2169.2634\n",
      "Epoch 44/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4710509.0000 - mae: 2168.8665\n",
      "Epoch 45/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4711178.0000 - mae: 2169.0046\n",
      "Epoch 46/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4709067.0000 - mae: 2168.5173\n",
      "Epoch 47/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4706153.0000 - mae: 2167.8340\n",
      "Epoch 48/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4708896.0000 - mae: 2168.4712\n",
      "Epoch 49/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4707383.0000 - mae: 2168.1362\n",
      "Epoch 50/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4703864.0000 - mae: 2167.3105\n",
      "Epoch 51/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4705263.5000 - mae: 2167.6311\n",
      "Epoch 52/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4703284.0000 - mae: 2167.1816\n",
      "Epoch 53/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4701859.0000 - mae: 2166.8628\n",
      "Epoch 54/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4697590.0000 - mae: 2165.8853\n",
      "Epoch 55/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 4701518.0000 - mae: 2166.7588\n",
      "Epoch 56/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 4703302.5000 - mae: 2167.1875\n",
      "Epoch 57/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4700763.5000 - mae: 2166.5996\n",
      "Epoch 58/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4697758.0000 - mae: 2165.9160\n",
      "Epoch 59/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4695508.0000 - mae: 2165.3862\n",
      "Epoch 60/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4699323.5000 - mae: 2166.2776\n",
      "Epoch 61/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4696840.0000 - mae: 2165.7100\n",
      "Epoch 62/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4695530.5000 - mae: 2165.3840\n",
      "Epoch 63/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 4696827.0000 - mae: 2165.6797\n",
      "Epoch 64/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4694782.0000 - mae: 2165.2036\n",
      "Epoch 65/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4696301.0000 - mae: 2165.5667\n",
      "Epoch 66/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4696072.0000 - mae: 2165.5266\n",
      "Epoch 67/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4691624.5000 - mae: 2164.4995\n",
      "Epoch 68/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4695227.0000 - mae: 2165.3364\n",
      "Epoch 69/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 4691089.0000 - mae: 2164.3411\n",
      "Epoch 70/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4690204.0000 - mae: 2164.1736\n",
      "Epoch 71/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 4689014.0000 - mae: 2163.8608\n",
      "Epoch 72/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4691255.0000 - mae: 2164.4009\n",
      "Epoch 73/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4689970.0000 - mae: 2164.0850\n",
      "Epoch 74/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 4689147.5000 - mae: 2163.9131\n",
      "Epoch 75/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 4689168.0000 - mae: 2163.9028\n",
      "Epoch 76/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4689687.0000 - mae: 2164.0503\n",
      "Epoch 77/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4687724.0000 - mae: 2163.6147\n",
      "Epoch 78/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4684393.5000 - mae: 2162.8181\n",
      "Epoch 79/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 4686794.0000 - mae: 2163.3625\n",
      "Epoch 80/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4685573.5000 - mae: 2163.0898\n",
      "Epoch 81/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4688353.0000 - mae: 2163.7356\n",
      "Epoch 82/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4685943.0000 - mae: 2163.1831\n",
      "Epoch 83/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4683510.5000 - mae: 2162.6035\n",
      "Epoch 84/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4685652.0000 - mae: 2163.1133\n",
      "Epoch 85/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4688377.0000 - mae: 2163.6924\n",
      "Epoch 86/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 4683860.0000 - mae: 2162.6909\n",
      "Epoch 87/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 4681633.5000 - mae: 2162.1692\n",
      "Epoch 88/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 4680194.0000 - mae: 2161.8438\n",
      "Epoch 89/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 4681154.0000 - mae: 2162.0986\n",
      "Epoch 90/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 4680845.5000 - mae: 2162.0132\n",
      "Epoch 91/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 4681640.0000 - mae: 2162.1768\n",
      "Epoch 92/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4679777.0000 - mae: 2161.7654\n",
      "Epoch 93/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4679214.5000 - mae: 2161.6372\n",
      "Epoch 94/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 4678197.0000 - mae: 2161.4009\n",
      "Epoch 95/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 4676939.5000 - mae: 2161.1016\n",
      "Epoch 96/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4677819.0000 - mae: 2161.3118\n",
      "Epoch 97/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4678815.5000 - mae: 2161.5210\n",
      "Epoch 98/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 4675589.5000 - mae: 2160.8140\n",
      "Epoch 99/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4674011.0000 - mae: 2160.4065\n",
      "Epoch 100/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 4674205.0000 - mae: 2160.4487\n",
      "Epoch 101/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 4675783.0000 - mae: 2160.8142\n",
      "Epoch 102/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 4674488.0000 - mae: 2160.5190\n",
      "Epoch 103/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step - loss: 4675840.5000 - mae: 2160.8601\n",
      "Epoch 104/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 4674207.5000 - mae: 2160.4763\n",
      "Epoch 105/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 4674916.0000 - mae: 2160.6121\n",
      "Epoch 106/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 4673848.0000 - mae: 2160.4080\n",
      "Epoch 107/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 4671120.0000 - mae: 2159.7231\n",
      "Epoch 108/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4672052.5000 - mae: 2159.9688\n",
      "Epoch 109/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 4670365.0000 - mae: 2159.5933\n",
      "Epoch 110/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 4668301.0000 - mae: 2159.0857\n",
      "Epoch 111/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4671802.5000 - mae: 2159.9189\n",
      "Epoch 112/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 4669350.0000 - mae: 2159.3459\n",
      "Epoch 113/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4668537.0000 - mae: 2159.1406\n",
      "Epoch 114/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4671849.0000 - mae: 2159.9243\n",
      "Epoch 115/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4668134.0000 - mae: 2159.0454\n",
      "Epoch 116/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4664073.0000 - mae: 2158.1064\n",
      "Epoch 117/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4662098.0000 - mae: 2157.6526\n",
      "Epoch 118/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4667366.0000 - mae: 2158.8794\n",
      "Epoch 119/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4667582.0000 - mae: 2158.8887\n",
      "Epoch 120/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4663560.5000 - mae: 2158.0024\n",
      "Epoch 121/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4668521.0000 - mae: 2159.1602\n",
      "Epoch 122/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4662063.0000 - mae: 2157.6624\n",
      "Epoch 123/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4666687.0000 - mae: 2158.6963\n",
      "Epoch 124/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 4663707.0000 - mae: 2158.0203\n",
      "Epoch 125/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4666540.0000 - mae: 2158.6750\n",
      "Epoch 126/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 4660916.0000 - mae: 2157.3826\n",
      "Epoch 127/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4662568.5000 - mae: 2157.7485\n",
      "Epoch 128/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4659178.0000 - mae: 2156.9819\n",
      "Epoch 129/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 4663329.5000 - mae: 2157.9580\n",
      "Epoch 130/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 4661955.0000 - mae: 2157.6367\n",
      "Epoch 131/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4664296.5000 - mae: 2158.1621\n",
      "Epoch 132/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4662167.5000 - mae: 2157.6650\n",
      "Epoch 133/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4661169.0000 - mae: 2157.4341\n",
      "Epoch 134/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4657070.5000 - mae: 2156.4839\n",
      "Epoch 135/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4657206.0000 - mae: 2156.5110\n",
      "Epoch 136/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4655659.0000 - mae: 2156.1509\n",
      "Epoch 137/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4660325.0000 - mae: 2157.2427\n",
      "Epoch 138/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4655343.0000 - mae: 2156.0876\n",
      "Epoch 139/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4658447.0000 - mae: 2156.8052\n",
      "Epoch 140/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4657567.0000 - mae: 2156.5955\n",
      "Epoch 141/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4656383.0000 - mae: 2156.3145\n",
      "Epoch 142/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4655760.5000 - mae: 2156.2051\n",
      "Epoch 143/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4653546.0000 - mae: 2155.6890\n",
      "Epoch 144/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4653978.0000 - mae: 2155.7827\n",
      "Epoch 145/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4655424.0000 - mae: 2156.1030\n",
      "Epoch 146/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4652656.5000 - mae: 2155.4333\n",
      "Epoch 147/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 4653817.0000 - mae: 2155.7344\n",
      "Epoch 148/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 4658258.0000 - mae: 2156.7832\n",
      "Epoch 149/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4653414.0000 - mae: 2155.6526\n",
      "Epoch 150/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4650627.0000 - mae: 2154.9980\n",
      "Epoch 151/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4653867.0000 - mae: 2155.7500\n",
      "Epoch 152/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4651759.0000 - mae: 2155.2808\n",
      "Epoch 153/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4652566.5000 - mae: 2155.4614\n",
      "Epoch 154/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4653033.5000 - mae: 2155.5364\n",
      "Epoch 155/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4649247.0000 - mae: 2154.6743\n",
      "Epoch 156/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4651432.0000 - mae: 2155.1387\n",
      "Epoch 157/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4648789.5000 - mae: 2154.5439\n",
      "Epoch 158/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4650055.0000 - mae: 2154.8809\n",
      "Epoch 159/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4646807.0000 - mae: 2154.1221\n",
      "Epoch 160/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4653948.0000 - mae: 2155.7488\n",
      "Epoch 161/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4651519.0000 - mae: 2155.1860\n",
      "Epoch 162/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4648319.0000 - mae: 2154.4634\n",
      "Epoch 163/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4643474.0000 - mae: 2153.3250\n",
      "Epoch 164/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4651592.0000 - mae: 2155.2380\n",
      "Epoch 165/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4648524.0000 - mae: 2154.4873\n",
      "Epoch 166/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 4648851.5000 - mae: 2154.5784\n",
      "Epoch 167/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4645505.0000 - mae: 2153.8140\n",
      "Epoch 168/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4643146.0000 - mae: 2153.2534\n",
      "Epoch 169/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4639133.5000 - mae: 2152.3477\n",
      "Epoch 170/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4639035.0000 - mae: 2152.3384\n",
      "Epoch 171/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4641952.5000 - mae: 2152.9890\n",
      "Epoch 172/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4638322.0000 - mae: 2152.1543\n",
      "Epoch 173/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4644253.5000 - mae: 2153.4893\n",
      "Epoch 174/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4643445.5000 - mae: 2153.3350\n",
      "Epoch 175/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4643494.5000 - mae: 2153.3501\n",
      "Epoch 176/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4641365.5000 - mae: 2152.8467\n",
      "Epoch 177/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 4639926.0000 - mae: 2152.5361\n",
      "Epoch 178/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4637809.0000 - mae: 2152.0398\n",
      "Epoch 179/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4645112.5000 - mae: 2153.7026\n",
      "Epoch 180/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4636842.5000 - mae: 2151.8047\n",
      "Epoch 181/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4639162.0000 - mae: 2152.3779\n",
      "Epoch 182/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4640336.0000 - mae: 2152.5601\n",
      "Epoch 183/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4640471.5000 - mae: 2152.6465\n",
      "Epoch 184/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4637910.0000 - mae: 2152.0366\n",
      "Epoch 185/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4638574.0000 - mae: 2152.2051\n",
      "Epoch 186/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4637577.5000 - mae: 2151.9119\n",
      "Epoch 187/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4637045.5000 - mae: 2151.8086\n",
      "Epoch 188/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4633353.5000 - mae: 2151.0073\n",
      "Epoch 189/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4638472.0000 - mae: 2152.1616\n",
      "Epoch 190/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4633404.0000 - mae: 2151.0198\n",
      "Epoch 191/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4633370.0000 - mae: 2150.9819\n",
      "Epoch 192/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4632260.0000 - mae: 2150.7485\n",
      "Epoch 193/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4638758.5000 - mae: 2152.2297\n",
      "Epoch 194/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4633732.0000 - mae: 2151.0945\n",
      "Epoch 195/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4630722.5000 - mae: 2150.3411\n",
      "Epoch 196/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4638301.5000 - mae: 2152.1411\n",
      "Epoch 197/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4627862.5000 - mae: 2149.6973\n",
      "Epoch 198/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4630393.0000 - mae: 2150.2944\n",
      "Epoch 199/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4628778.5000 - mae: 2149.9297\n",
      "Epoch 200/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 4626267.0000 - mae: 2149.3877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16dec8770>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T09:49:07.152552Z",
     "start_time": "2024-12-16T09:49:07.143466Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()",
   "id": "3b5c11d31d90eb9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_16\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_18 (\u001B[38;5;33mLSTM\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)            │        \u001B[38;5;34m45,600\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m101\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">45,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m137,105\u001B[0m (535.57 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,105</span> (535.57 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m45,701\u001B[0m (178.52 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,701</span> (178.52 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m91,404\u001B[0m (357.05 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,404</span> (357.05 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 217
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T09:49:07.290654Z",
     "start_time": "2024-12-16T09:49:07.187766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Predict on test data\n",
    "predictions = model.predict(test_training_data)\n",
    "\n",
    "print(f\"predictions: {predictions}\\nactual race times: {test_racing_data}\")\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(test_racing_data, predictions)\n",
    "mse = mean_squared_error(test_racing_data, predictions)\n",
    "r2 = r2_score(test_racing_data, predictions)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared (R2): {r2}\")"
   ],
   "id": "7f71c4d9db3b2866",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 76ms/step\n",
      "predictions: [[32.984356]\n",
      " [32.98105 ]]\n",
      "actual race times: [2339. 2328.]\n",
      "Mean Squared Error (MSE): 5292410.069035161\n",
      "Mean Absolute Error (MAE): 2300.517297744751\n",
      "R-squared (R2): -174954.70476149293\n"
     ]
    }
   ],
   "execution_count": 218
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
